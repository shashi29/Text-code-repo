{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code_02",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hb8E5xYpjN7-",
        "colab_type": "code",
        "outputId": "bd1f0161-8386-45e8-bddd-2965900cd8e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
        "!pip install fastai"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Requirement already satisfied: torch_nightly in /usr/local/lib/python3.6/dist-packages (1.0.0.dev20181206)\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.46)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.6.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.0)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.18)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from fastai) (3.6.6)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.16.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.0.3)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.1.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.2.2.post3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (19.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.1.post2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.18.4)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.1.20)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.2)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (6.12.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.9.6)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.2.9)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.35)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.1)\n",
            "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2018.1.10)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.3.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.0.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->fastai) (1.11.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2018.11.29)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.4.3.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (4.28.1)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0.1)\n",
            "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.5.6)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (1.10.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->fastai) (40.8.0)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pmADbtvhrlsR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6bcsg0U1rp7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f6156c47-ecd5-48cd-c465-aa459f249bc8"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "link = 'https://drive.google.com/open?id=1udJeq9cYA5BTagIh2I_TcBiqYn8FxJaj'\n",
        "fluff, id = link.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.csv')  \n",
        "train_df = pd.read_csv('train.csv',sep='~')\n",
        "link = 'https://drive.google.com/open?id=1P0NgTOvLwUznerU0grO-dU-6ASCKgeBn'\n",
        "fluff, id = link.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test.csv')  \n",
        "test_df = pd.read_csv('test.csv',sep='~')\n",
        "test_df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Description</th>\n",
              "      <th>Browser_Used</th>\n",
              "      <th>Device_Used</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9602</td>\n",
              "      <td>A friend and I stayed in this hotel when we we...</td>\n",
              "      <td>Edge</td>\n",
              "      <td>Desktop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8749</td>\n",
              "      <td>I enjoy staying here when I have early flights...</td>\n",
              "      <td>Google Chrome</td>\n",
              "      <td>Mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15500</td>\n",
              "      <td>I stopped off in Seattle during a train tour o...</td>\n",
              "      <td>Chrome</td>\n",
              "      <td>Mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5495</td>\n",
              "      <td>I have stayed at this hotel - or - times now f...</td>\n",
              "      <td>Mozilla Firefox</td>\n",
              "      <td>Desktop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18570</td>\n",
              "      <td>Excellent location with hop on hop off city tr...</td>\n",
              "      <td>Edge</td>\n",
              "      <td>Mobile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   User_ID                                        Description  \\\n",
              "0     9602  A friend and I stayed in this hotel when we we...   \n",
              "1     8749  I enjoy staying here when I have early flights...   \n",
              "2    15500  I stopped off in Seattle during a train tour o...   \n",
              "3     5495  I have stayed at this hotel - or - times now f...   \n",
              "4    18570  Excellent location with hop on hop off city tr...   \n",
              "\n",
              "      Browser_Used Device_Used  \n",
              "0             Edge     Desktop  \n",
              "1    Google Chrome      Mobile  \n",
              "2           Chrome      Mobile  \n",
              "3  Mozilla Firefox     Desktop  \n",
              "4             Edge      Mobile  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "lUP9tqYHsi6B",
        "colab_type": "code",
        "outputId": "718044f7-67c0-49ce-d065-0a2908ffe471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D ,GRU\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "trUxLbG44Lmq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next steps are as follows:\n",
        "\n",
        "Split the training dataset into train and val sample. Cross validation is a time consuming process and so let us do simple train val split.\n",
        "Fill up the missing values in the text column with 'na'\n",
        "Tokenize the text column and convert them to vector sequences\n",
        "Pad the sequence as needed - if the number of words in the text is greater than 'max_len' trunacate them to 'max_len' or if the number of words in the text is lesser than 'max_len' add zeros for remaining values."
      ]
    },
    {
      "metadata": {
        "id": "wLc-nnDGtZ6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stars_dict = {'Good':1,'Bad':0}\n",
        "train_df[\"Is_Response\"] = train_df['Is_Response'].replace(stars_dict,regex=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g3xEfqwttzvY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## split to train and val\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=29)\n",
        "\n",
        "## some config values \n",
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 100 # max number of words in a question to use\n",
        "\n",
        "## fill up the missing values\n",
        "train_X = train_df[\"Description\"].fillna(\"_na_\").values\n",
        "val_X = val_df[\"Description\"].fillna(\"_na_\").values\n",
        "test_X = test_df[\"Description\"].fillna(\"_na_\").values\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_X))\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "val_X = tokenizer.texts_to_sequences(val_X)\n",
        "test_X = tokenizer.texts_to_sequences(test_X)\n",
        "\n",
        "## Pad the sentences \n",
        "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
        "\n",
        "## Get the target values\n",
        "train_y = train_df['Is_Response'].values\n",
        "val_y = val_df['Is_Response'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lfEs88_i4-23",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Without Pretrained Embeddings:\n",
        "\n",
        "Now that we are done with all the necessary preprocessing steps, we can first train a Bidirectional GRU model. We will not use any pre-trained word embeddings for this model and the embeddings will be learnt from scratch. Please check out the model summary for the details of the layers used."
      ]
    },
    {
      "metadata": {
        "id": "mrMjgdafuaY8",
        "colab_type": "code",
        "outputId": "181097b5-7b39-475e-8787-0d88084fc688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "inp = Input(shape=(maxlen,))\n",
        "x = Embedding(max_features, embed_size)(inp)\n",
        "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 100, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 100, 128)          140544    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 15,142,625\n",
            "Trainable params: 15,142,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7BvnK7c25NEo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "52da77f1-5650-4222-d7dc-497e31c93667"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "## Train the model \n",
        "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 27154 samples, validate on 3018 samples\n",
            "Epoch 1/2\n",
            "27154/27154 [==============================] - 11s 399us/step - loss: 0.5606 - acc: 0.7073 - val_loss: 0.4004 - val_acc: 0.8472\n",
            "Epoch 2/2\n",
            "27154/27154 [==============================] - 5s 195us/step - loss: 0.3510 - acc: 0.8530 - val_loss: 0.3137 - val_acc: 0.8711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f72a3aa6b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "zhcBtZN9AB_K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let us get the validation sample predictions and also get the best threshold for F1 score."
      ]
    },
    {
      "metadata": {
        "id": "9FbWy6MJ_7CK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "55883e9f-37cb-4516-b541-8a695313833e"
      },
      "cell_type": "code",
      "source": [
        "pred_noemb_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3018/3018 [==============================] - 0s 73us/step\n",
            "F1 score at threshold 0.1 is 0.8302114803625378\n",
            "F1 score at threshold 0.11 is 0.839169381107492\n",
            "F1 score at threshold 0.12 is 0.8457588827274595\n",
            "F1 score at threshold 0.13 is 0.8531671858774662\n",
            "F1 score at threshold 0.14 is 0.8619457869300273\n",
            "F1 score at threshold 0.15 is 0.8690299299511781\n",
            "F1 score at threshold 0.16 is 0.8747855917667239\n",
            "F1 score at threshold 0.17 is 0.8792207792207791\n",
            "F1 score at threshold 0.18 is 0.8840358156802796\n",
            "F1 score at threshold 0.19 is 0.8859649122807017\n",
            "F1 score at threshold 0.2 is 0.8877618522601984\n",
            "F1 score at threshold 0.21 is 0.8909574468085106\n",
            "F1 score at threshold 0.22 is 0.8927458834000891\n",
            "F1 score at threshold 0.23 is 0.8936550491510278\n",
            "F1 score at threshold 0.24 is 0.8954219030520646\n",
            "F1 score at threshold 0.25 is 0.8958380202474692\n",
            "F1 score at threshold 0.26 is 0.8966606498194948\n",
            "F1 score at threshold 0.27 is 0.8974417025130179\n",
            "F1 score at threshold 0.28 is 0.899432463110102\n",
            "F1 score at threshold 0.29 is 0.90154968094804\n",
            "F1 score at threshold 0.3 is 0.9021490626428897\n",
            "F1 score at threshold 0.31 is 0.9032110091743119\n",
            "F1 score at threshold 0.32 is 0.9037887485648679\n",
            "F1 score at threshold 0.33 is 0.904367816091954\n",
            "F1 score at threshold 0.34 is 0.9038949066605209\n",
            "F1 score at threshold 0.35 is 0.9039704524469068\n",
            "F1 score at threshold 0.36 is 0.9045854562297361\n",
            "F1 score at threshold 0.37 is 0.904109589041096\n",
            "F1 score at threshold 0.38 is 0.904517931998137\n",
            "F1 score at threshold 0.39 is 0.9057396173588428\n",
            "F1 score at threshold 0.4 is 0.9069223573433116\n",
            "F1 score at threshold 0.41 is 0.9073856975381008\n",
            "F1 score at threshold 0.42 is 0.9078514339445228\n",
            "F1 score at threshold 0.43 is 0.9063900023579345\n",
            "F1 score at threshold 0.44 is 0.905776515151515\n",
            "F1 score at threshold 0.45 is 0.9065021357380161\n",
            "F1 score at threshold 0.46 is 0.9055436592909826\n",
            "F1 score at threshold 0.47 is 0.905579399141631\n",
            "F1 score at threshold 0.48 is 0.9079167663238459\n",
            "F1 score at threshold 0.49 is 0.9079136690647481\n",
            "F1 score at threshold 0.5 is 0.9065128574861812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SMGP26QAALSR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9a8ddfe-faba-45b8-edde-2cc7118cb8c0"
      },
      "cell_type": "code",
      "source": [
        "#Now let us get the test set predictions as well and save them\n",
        "pred_noemb_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8760/8760 [==============================] - 0s 43us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "St_WGG30AhtS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "link = 'https://drive.google.com/open?id=1Dci_Yju-vCMM9o7yEU9p7QEND28PUmFs'\n",
        "fluff, id = link.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('sample_submission.csv')  \n",
        "submission_1 = pd.read_csv('sample_submission.csv',sep='~')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j1A1E_uXBYHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "32de7b91-8db5-4538-a9bf-335e486e7e8a"
      },
      "cell_type": "code",
      "source": [
        "check_1 = (pred_noemb_test_y>0.15).astype(int)\n",
        "out_df = pd.DataFrame({\"qid\":test_df[\"User_ID\"].values})\n",
        "out_df['Is_Response'] = check_1\n",
        "stars_dict = {1:'Good',0:'Bad'}\n",
        "out_df[\"Is_Response\"] = out_df['Is_Response'].replace(stars_dict,regex=True)\n",
        "out_df.to_csv(\"submission_1.csv\", index=False)\n",
        "out_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>Is_Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9602</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8749</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15500</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5495</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18570</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     qid Is_Response\n",
              "0   9602        Good\n",
              "1   8749        Good\n",
              "2  15500        Good\n",
              "3   5495        Good\n",
              "4  18570        Good"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}